{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First method is _filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1663]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# This is origin code\n",
    "\"\"\"\n",
    "def _filter(self):\n",
    "        audiopaths_and_text_new = []\n",
    "        lengths = []\n",
    "        for audiopath, text in self.audiopaths_and_text:\n",
    "            # we filter the text with appropriate length\n",
    "            if self.min_text_len <= len(text) and len(text) <= self.max_text_len:\n",
    "                audiopaths_and_text_new.append([audiopath, text])\n",
    "                # lengths store the length of spectrogram\n",
    "                # length of spectrogram is length of audio // hop_length\n",
    "                lengths.append(os.path.getsize(audiopath) // (2 * self.hop_length))\n",
    "        self.audiopaths_and_text = audiopaths_and_text_new\n",
    "        self.lengths = lengths\n",
    "\"\"\"\n",
    "# after processed by load_filepaths_and_text in data_utils and utils\n",
    "# the audiopaths_and_text will be like this.\n",
    "\n",
    "lengths = []\n",
    "hop_length = 256\n",
    "min_text_len = 1\n",
    "max_text_len = 190 # the same as original vits code.\n",
    "audiopaths_and_text = [('audio/LJ001-0001.wav','Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition')]\n",
    "def _filter():\n",
    "        global audiopaths_and_text, lengths\n",
    "        audiopaths_and_text_new = []\n",
    "        local_length = []\n",
    "        for audiopath, text in audiopaths_and_text:\n",
    "            # we filter the text with appropriate length\n",
    "            if min_text_len <= len(text) and len(text) <= max_text_len:\n",
    "                audiopaths_and_text_new.append([audiopath, text])\n",
    "                # lengths store the length of spectrogram\n",
    "                # length of spectrogram is length of audio // hop_length\n",
    "                local_length.append(os.path.getsize(audiopath) // (2 * hop_length))\n",
    "        audiopaths_and_text = audiopaths_and_text_new\n",
    "        lengths = local_length\n",
    "_filter()\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
